{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydatasci\n",
      "  Using cached https://files.pythonhosted.org/packages/18/5f/4e07fc0aae654eac617ad887efe1676e87dac4570c9d7ebfa19462f79a9a/pydatasci-0.0.55-py3-none-any.whl\n",
      "Requirement already satisfied: keras in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from pydatasci) (2.4.3)\n",
      "Requirement already satisfied: appdirs in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from pydatasci) (1.4.4)\n",
      "Requirement already satisfied: pandas in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from pydatasci) (1.1.4)\n",
      "Requirement already satisfied: plotly in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from pydatasci) (4.12.0)\n",
      "Requirement already satisfied: numpy in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from pydatasci) (1.18.5)\n",
      "Requirement already satisfied: peewee in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from pydatasci) (3.14.0)\n",
      "Requirement already satisfied: pyarrow in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from pydatasci) (2.0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from pydatasci) (0.23.2)\n",
      "Requirement already satisfied: pyyaml in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from keras->pydatasci) (5.3.1)\n",
      "Requirement already satisfied: h5py in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from keras->pydatasci) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from keras->pydatasci) (1.5.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from pandas->pydatasci) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from pandas->pydatasci) (2020.4)\n",
      "Requirement already satisfied: six in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from plotly->pydatasci) (1.15.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from plotly->pydatasci) (1.3.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from scikit-learn->pydatasci) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/layne/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages (from scikit-learn->pydatasci) (2.1.0)\n",
      "Installing collected packages: pydatasci\n",
      "Successfully installed pydatasci-0.0.55\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydatasci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! jupyter labextension install jupyterlab-plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from keras.metrics import *\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Welcome to PyDataSci.\n",
      "To get started, run `pds.create_folder()` followed by `pds.create_config()` in Python shell.\n",
      "\n",
      "\n",
      "=> Info - it appears the following folder does not exist on your system:\n",
      "/Users/layne/Library/Application Support/pydatasci/\n",
      "\n",
      "\n",
      "=> Fix - you can attempt to fix this by running `pds.create_folder()`.\n",
      "\n",
      "\n",
      "=> Success - created folder at file path:\n",
      "/Users/layne/Library/Application Support/pydatasci/\n",
      "\n",
      "\n",
      "=> Fix - now try running `pds.create_config()` again.\n",
      "\n",
      "\n",
      "=> Success - the following file path already exists on your system:\n",
      "/Users/layne/Library/Application Support/pydatasci/\n",
      "\n",
      "\n",
      "=> Success - created config file for settings at path:\n",
      "/Users/layne/Library/Application Support/pydatasci/config.json\n",
      "\n",
      "\n",
      "=> Success - created database file for machine learning metrics at path:\n",
      "/Users/layne/Library/Application Support/pydatasci/aidb.sqlite3\n",
      "\n",
      "\n",
      "=> Success - created the following tables within database:\n",
      "['algorithm', 'batch', 'dataset', 'featureset', 'fold', 'foldset', 'hyperparamcombo', 'hyperparamset', 'job', 'label', 'preprocess', 'result', 'splitset']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pydatasci as pds\n",
    "pds.create_folder()\n",
    "pds.create_config()\n",
    "\n",
    "from pydatasci import aidb\n",
    "aidb.create_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest file, dataframe, or array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/layne/Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pydatasci/data/iris.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b837905cee03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m,\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tsv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tab-separated plants'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;34m,\u001b[0m \u001b[0mperform_gzip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages/pydatasci/aidb/__init__.py\u001b[0m in \u001b[0;36mfrom_pandas\u001b[0;34m(dataframe, name, file_format, perform_gzip, dtype, rename_columns)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_file_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_column_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrename_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/pydatasci_test/lib/python3.7/site-packages/pydatasci/aidb/__init__.py\u001b[0m in \u001b[0;36mcheck_column_count\u001b[0;34m(user_columns, structure)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck_column_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                 \u001b[0mcol_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m                 \u001b[0mstructure_col_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol_count\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mstructure_col_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "dataset = aidb.Dataset.from_pandas(\n",
    "\tdataframe = df\n",
    "\t, file_format = 'tsv'\n",
    "\t, name = 'tab-separated plants'\n",
    "\t, perform_gzip = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'target'\n",
    "\n",
    "label = dataset.make_label(columns=[label_name])\n",
    "\n",
    "featureset = dataset.make_featureset(exclude_columns=[label_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign sample IDs to training, validation, and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = featureset.make_splitset(\n",
    "\tlabel_id = label.id\n",
    "\t, size_test = 0.20\n",
    "\t, size_validation = 0.12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldset = splitset.make_foldset(fold_count=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_features = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_labels = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = aidb.Preprocess.from_splitset(\n",
    "    splitset_id = splitset.id\n",
    "    , description = \"Scale features and OHE labels.\"\n",
    "    , encoder_features = encoder_features\n",
    "    , encoder_labels = encoder_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_model_build(**hyperparameters):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_shape=(4,), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(hyperparameters['l2_neuron_count'], activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(3, activation='softmax', name='output'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy'\n",
    "        , optimizer=hyperparameters['optimizer']\n",
    "        , metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_model_train(model, samples_train, samples_evaluate, **hyperparameters):\n",
    "    model.fit(\n",
    "        samples_train[\"features\"], samples_train[\"labels\"]\n",
    "        , validation_data = (\n",
    "            samples_evaluate[\"features\"], samples_evaluate[\"labels\"]\n",
    "        )\n",
    "        , verbose = 0\n",
    "        , batch_size = 3\n",
    "        , epochs = hyperparameters['epochs']\n",
    "        , callbacks=[History()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_model_predict(model, samples_predict):\n",
    "    probabilities = model.predict(samples_predict['features'])\n",
    "    predictions = np.argmax(probabilities, axis=-1)\n",
    "    \n",
    "    return predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_model_loss(model, samples_evaluate):\n",
    "    loss, _ = model.evaluate(samples_evaluate['features'], samples_evaluate['labels'], verbose=0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"l2_neuron_count\": [13, 9]\n",
    "    , \"optimizer\": [\"adamax\", \"adam\"]\n",
    "    , \"epochs\": [60, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = aidb.Algorithm.create(\n",
    "    library = \"Keras\"\n",
    "    , analysis_type = \"classification_multi\"\n",
    "    , description = \"dense, 2 layers, medium height\"\n",
    "\t, function_model_build = function_model_build\n",
    "\t, function_model_train = function_model_train\n",
    "    , function_model_predict = function_model_predict\n",
    "    , function_model_loss = function_model_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamset = aidb.Hyperparamset.from_algorithm(\n",
    "    algorithm_id = algorithm.id\n",
    "    , preprocess_id = preprocess.id\n",
    "    , description = \"experimenting with number of epochs\"\n",
    "\t, hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = aidb.Batch.from_algorithm(\n",
    "    algorithm_id = algorithm.id\n",
    "    , splitset_id = splitset.id\n",
    "    , hyperparamset_id = hyperparamset.id\n",
    "    , foldset_id = None #foldset.id\n",
    "    , only_folded_training = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.run_jobs(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.stop_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.get_statuses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = aidb.Batch.get_by_id(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.metrics_to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.jobs[0].results[0].plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.jobs[0].results[0].plot_roc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.jobs[0].results[0].plot_precision_recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.jobs[0].results[0].plot_precision_recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.jobs[0].results[0].plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.plot_performance(max_loss=0.40, min_metric_2=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
