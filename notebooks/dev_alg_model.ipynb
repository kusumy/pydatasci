{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6 (default, Aug  9 2020, 21:13:30) \n",
      "[Clang 11.0.3 (clang-1103.0.32.62)] darwin /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/bin/python3.7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version, sys.platform, sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/layne/Desktop/pydatasci'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/layne/Desktop/pydatasci')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pydatasci as pds\n",
    "from pydatasci import aidb\n",
    "import os, sqlite3, io, gzip \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "from pyarrow import csv as pc\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "\n",
    "import keras\n",
    "from keras import metrics\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import History\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Success - deleted database file at path:\n",
      "/Users/layne/Library/Application Support/pydatasci/aidb.sqlite3\n",
      "\n",
      "\n",
      "=> Success - created database file for machine learning metrics at path:\n",
      "/Users/layne/Library/Application Support/pydatasci/aidb.sqlite3\n",
      "\n",
      "\n",
      "=> Success - created the following tables within database:\n",
      "['algorithm', 'batch', 'dataset', 'featureset', 'fold', 'foldset', 'hyperparamcombo', 'hyperparamset', 'job', 'label', 'preprocess', 'result', 'splitset']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload; aidb.delete_db(True); reload(aidb); aidb.create_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = aidb.Dataset.from_file(\n",
    "\tpath = 'data/iris.tsv' \n",
    "\t,file_format = 'tsv'\n",
    "\t,name = 'tab-separated plants'\n",
    "\t,perform_gzip = True\n",
    "    ,dtype = 'float64'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset.make_label(columns=[label_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = dataset.make_featureset(exclude_columns=[label_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = featureset.make_splitset(\n",
    "\tlabel_id = label.id\n",
    "\t, size_test = 0.20\n",
    "\t, size_validation = 0.12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foldset = splitset.make_foldset(fold_count=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aidb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Preprocess (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to have to make sure that I am uniformly importing the packages. \n",
    "`from sklearn.preprocessing import *`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_features = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_labels = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params_encode_labels = {\"sparse\": [False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_model_build(**hyperparameters):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_shape=(4,), activation='relu', kernel_initializer='he_uniform', name='fc1')) # first hidden layer\n",
    "    model.add(Dense(hyperparameters['l2_neuron_count'], activation='relu', kernel_initializer='he_uniform', name='fc2'))\n",
    "    model.add(Dense(3, activation='softmax', name='output'))\n",
    "\n",
    "    model.compile(optimizer=hyperparameters['optimizer'], loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_model_train(model, samples_train, samples_evaluate, **hyperparameters):\n",
    "    model.fit(\n",
    "        samples_train[\"features\"]\n",
    "        , samples_train[\"labels\"]\n",
    "        , validation_data = (\n",
    "            samples_evaluate[\"features\"]\n",
    "            , samples_evaluate[\"labels\"]\n",
    "        )\n",
    "        , verbose = 0\n",
    "        , batch_size = 3\n",
    "        , epochs = hyperparameters['epochs']\n",
    "        , callbacks=[History()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_model_evaluate(model, samples_evaluate, **hyperparameters):\n",
    "    results = model.evaluate(samples_evaluate[\"features\"], samples_evaluate[\"labels\"], verbose=0)\n",
    "    #print(\"Loss = \" + str(results[0]) + \" // Accuracy = \" + str(results[1]) )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters = {\n",
    "#     \"l1_neuron_count\": [9, 18]\n",
    "#     , \"l2_neuron_count\": [9, 18]\n",
    "#     , \"optimizer\": [\"adamax\", \"adam\"]\n",
    "#     , \"epochs\": [30, 60, 90]\n",
    "#     , \"batch_size\": [3, 5]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"l2_neuron_count\": [9, 18]\n",
    "    , \"optimizer\": [\"adamax\", \"adam\"]\n",
    "    , \"epochs\": [10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage the Experiment and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = aidb.Algorithm.create(\n",
    "    library = \"Keras\"\n",
    "    , description = \"dense, 2 layers, medium height\"\n",
    "\t, function_model_build = function_model_build\n",
    "\t, function_model_train = function_model_train\n",
    "\t, function_model_evaluate = function_model_evaluate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = aidb.Preprocess.from_splitset(\n",
    "    splitset_id = splitset.id\n",
    "    , description = \"standard scaling on features\"\n",
    "    , encoder_features = encoder_features\n",
    "    , encoder_labels = encoder_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamset = aidb.Hyperparamset.from_algorithm(\n",
    "    algorithm_id = algorithm.id\n",
    "    , preprocess_id = preprocess.id\n",
    "    , description = \"experimenting with number of epochs\"\n",
    "\t, hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparamset.hyperparamcombo_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = aidb.Batch.from_algorithm(\n",
    "    algorithm_id = algorithm.id\n",
    "    , splitset_id = splitset.id\n",
    "    , hyperparamset_id = hyperparamset.id\n",
    "    , foldset_id = None #foldset.id\n",
    "    , only_folded_training = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.job_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 8/8 [00:10<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "batch.run_jobs(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Queued',\n",
       " 2: 'Queued',\n",
       " 3: 'Queued',\n",
       " 4: 'Queued',\n",
       " 5: 'Queued',\n",
       " 6: 'Queued',\n",
       " 7: 'Queued',\n",
       " 8: 'Queued'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.get_statuses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch.stop_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x14da40990>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.jobs[0].results[0].get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [0.8290887475013733, 0.5686274766921997],\n",
       " 'validation': [0.8197234272956848, 0.6111111044883728],\n",
       " 'test': [0.8392254710197449, 0.5666666626930237]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.jobs[0].results[0].evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.1361279487609863,\n",
       "  1.0814762115478516,\n",
       "  1.0396240949630737,\n",
       "  1.0023505687713623,\n",
       "  0.9693678021430969,\n",
       "  0.9382761120796204,\n",
       "  0.9110653400421143,\n",
       "  0.8860802054405212,\n",
       "  0.8626300096511841,\n",
       "  0.8403457999229431],\n",
       " 'accuracy': [0.343137264251709,\n",
       "  0.343137264251709,\n",
       "  0.3921568691730499,\n",
       "  0.4215686321258545,\n",
       "  0.44117647409439087,\n",
       "  0.45098039507865906,\n",
       "  0.47058823704719543,\n",
       "  0.5,\n",
       "  0.5098039507865906,\n",
       "  0.5490196347236633],\n",
       " 'val_loss': [1.0702990293502808,\n",
       "  1.0278077125549316,\n",
       "  0.9908008575439453,\n",
       "  0.957991898059845,\n",
       "  0.9270286560058594,\n",
       "  0.9018315076828003,\n",
       "  0.8793914318084717,\n",
       "  0.8583993911743164,\n",
       "  0.8385547995567322,\n",
       "  0.8197234272956848],\n",
       " 'val_accuracy': [0.3333333432674408,\n",
       "  0.3333333432674408,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5555555820465088,\n",
       "  0.5555555820465088,\n",
       "  0.5555555820465088,\n",
       "  0.6111111044883728,\n",
       "  0.6111111044883728]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.jobs[0].results[0].model_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = splitset.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = samples[\"train\"][\"features\"]\n",
    "validation_features = samples[\"validation\"][\"features\"]\n",
    "test_features = samples[\"test\"][\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = samples[\"train\"][\"labels\"]\n",
    "validation_labels = samples[\"validation\"][\"labels\"]\n",
    "test_labels = samples[\"test\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [None]\n",
    "fset = ['a','b','c']\n",
    "folds = folds + fset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On jobs need a `Job.from_hyperparamset()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Alternatively, pass in a dictionary of values for that keyword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Or just pass the params directly into the encoder function if you don't want to hypertune on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_labels = encoder.set_params(**encode_features_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_labels_trained = encoder_labels.fit(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = encoder_labels_trained.transform(train_labels)\n",
    "validation_labels = encoder_labels_trained.transform(validation_labels)\n",
    "test_labels = encoder_labels_trained.transform(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the preprocess object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = aidb.Preprocess.create(\n",
    "    encode_labels_function = encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_encoder = preprocess.preprocess_labels_function.set_params(**preprocess_features_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_labels_trained = feature_encoder.fit(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = encoder_labels_trained.transform(train_labels)\n",
    "validation_labels = encoder_labels_trained.transform(validation_labels)\n",
    "test_labels = encoder_labels_trained.transform(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^^ Now do the same, but with kwargs stored in the hyperparamset attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo - Does Pandas labels probably wants a series too, not a full dataframe? `.as_series()` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = splitset.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = samples[\"train\"][\"features\"]\n",
    "test_features = samples[\"test\"][\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = samples[\"train\"][\"labels\"]\n",
    "test_labels = samples[\"test\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "train_labels = encoder.fit_transform(train_labels)\n",
    "test_labels = encoder.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(13, input_shape=(4,), activation='relu', kernel_initializer='he_uniform', name='fc1')) # first hidden layer\n",
    "model.add(Dense(3, activation='softmax', name='output'))\n",
    "model.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 13)                65        \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 107\n",
      "Trainable params: 107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train():\n",
    "    model.fit(\n",
    "        train_features\n",
    "        , train_labels\n",
    "        , validation_data = (test_features, test_labels)\n",
    "        , verbose = 0\n",
    "        , batch_size = 6\n",
    "        , epochs = 60\n",
    "        , callbacks=[History()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.716982126235962,\n",
       "  1.6168975830078125,\n",
       "  1.5186580419540405,\n",
       "  1.4281631708145142,\n",
       "  1.3363103866577148,\n",
       "  1.2430486679077148,\n",
       "  1.1638587713241577,\n",
       "  1.0838406085968018,\n",
       "  1.0114461183547974,\n",
       "  0.9434520602226257,\n",
       "  0.883625328540802,\n",
       "  0.8264437913894653,\n",
       "  0.7812291979789734,\n",
       "  0.7397616505622864,\n",
       "  0.7080036997795105,\n",
       "  0.6793625950813293,\n",
       "  0.653673529624939,\n",
       "  0.6317193508148193,\n",
       "  0.6112250685691833,\n",
       "  0.594214141368866,\n",
       "  0.5785435438156128,\n",
       "  0.5647279620170593,\n",
       "  0.5523313879966736,\n",
       "  0.5398412346839905,\n",
       "  0.5295905470848083,\n",
       "  0.519515872001648,\n",
       "  0.5111671090126038,\n",
       "  0.5023576617240906,\n",
       "  0.4946964979171753,\n",
       "  0.4876684248447418,\n",
       "  0.48149698972702026,\n",
       "  0.4745713472366333,\n",
       "  0.4696151912212372,\n",
       "  0.4632842540740967,\n",
       "  0.4580068290233612,\n",
       "  0.4531033933162689,\n",
       "  0.4486708641052246,\n",
       "  0.443932443857193,\n",
       "  0.43989092111587524,\n",
       "  0.4355388283729553,\n",
       "  0.43247413635253906,\n",
       "  0.4281100928783417,\n",
       "  0.4246746897697449,\n",
       "  0.4213531017303467,\n",
       "  0.41772744059562683,\n",
       "  0.414745569229126,\n",
       "  0.4121265411376953,\n",
       "  0.40853163599967957,\n",
       "  0.4057258069515228,\n",
       "  0.40289509296417236,\n",
       "  0.4001345634460449,\n",
       "  0.39695343375205994,\n",
       "  0.3946003019809723,\n",
       "  0.3914310932159424,\n",
       "  0.38849788904190063,\n",
       "  0.3850972354412079,\n",
       "  0.3818965554237366,\n",
       "  0.3790714740753174,\n",
       "  0.3750483989715576,\n",
       "  0.3720117211341858],\n",
       " 'accuracy': [0.5196078419685364,\n",
       "  0.4901960790157318,\n",
       "  0.46078431606292725,\n",
       "  0.44117647409439087,\n",
       "  0.4215686321258545,\n",
       "  0.3921568691730499,\n",
       "  0.4117647111415863,\n",
       "  0.3921568691730499,\n",
       "  0.37254902720451355,\n",
       "  0.37254902720451355,\n",
       "  0.38235294818878174,\n",
       "  0.5098039507865906,\n",
       "  0.6666666865348816,\n",
       "  0.7058823704719543,\n",
       "  0.7058823704719543,\n",
       "  0.7058823704719543,\n",
       "  0.7254902124404907,\n",
       "  0.7352941036224365,\n",
       "  0.7549019455909729,\n",
       "  0.7549019455909729,\n",
       "  0.7549019455909729,\n",
       "  0.7745097875595093,\n",
       "  0.7647058963775635,\n",
       "  0.8039215803146362,\n",
       "  0.8235294222831726,\n",
       "  0.8235294222831726,\n",
       "  0.8235294222831726,\n",
       "  0.8333333134651184,\n",
       "  0.8333333134651184,\n",
       "  0.843137264251709,\n",
       "  0.843137264251709,\n",
       "  0.843137264251709,\n",
       "  0.8823529481887817,\n",
       "  0.8823529481887817,\n",
       "  0.8725489974021912,\n",
       "  0.8529411554336548,\n",
       "  0.8921568393707275,\n",
       "  0.8921568393707275,\n",
       "  0.8921568393707275,\n",
       "  0.8921568393707275,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9019607901573181,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9117646813392639,\n",
       "  0.9019607901573181,\n",
       "  0.9215686321258545,\n",
       "  0.9313725233078003,\n",
       "  0.9313725233078003,\n",
       "  0.9313725233078003],\n",
       " 'val_loss': [1.6748710870742798,\n",
       "  1.5763524770736694,\n",
       "  1.4885501861572266,\n",
       "  1.3933595418930054,\n",
       "  1.2979011535644531,\n",
       "  1.2110823392868042,\n",
       "  1.1276386976242065,\n",
       "  1.053981900215149,\n",
       "  0.9810962080955505,\n",
       "  0.91214919090271,\n",
       "  0.8484401106834412,\n",
       "  0.7988855838775635,\n",
       "  0.754207968711853,\n",
       "  0.7198306918144226,\n",
       "  0.6873101592063904,\n",
       "  0.6587241291999817,\n",
       "  0.6347720623016357,\n",
       "  0.6120635867118835,\n",
       "  0.5930618047714233,\n",
       "  0.5756774544715881,\n",
       "  0.5604771971702576,\n",
       "  0.546254575252533,\n",
       "  0.5339838266372681,\n",
       "  0.5218353271484375,\n",
       "  0.511107325553894,\n",
       "  0.5014868974685669,\n",
       "  0.4925357699394226,\n",
       "  0.48444780707359314,\n",
       "  0.4769481420516968,\n",
       "  0.46985676884651184,\n",
       "  0.46291905641555786,\n",
       "  0.4566105306148529,\n",
       "  0.45039188861846924,\n",
       "  0.4449313282966614,\n",
       "  0.44027474522590637,\n",
       "  0.4352361559867859,\n",
       "  0.430258572101593,\n",
       "  0.4259043335914612,\n",
       "  0.4218589663505554,\n",
       "  0.41744425892829895,\n",
       "  0.4130549132823944,\n",
       "  0.4093090295791626,\n",
       "  0.40587344765663147,\n",
       "  0.40278610587120056,\n",
       "  0.39918410778045654,\n",
       "  0.3957352638244629,\n",
       "  0.39316636323928833,\n",
       "  0.38982805609703064,\n",
       "  0.3868412971496582,\n",
       "  0.38374364376068115,\n",
       "  0.380710631608963,\n",
       "  0.37815913558006287,\n",
       "  0.3749738335609436,\n",
       "  0.3723362684249878,\n",
       "  0.36952438950538635,\n",
       "  0.36634865403175354,\n",
       "  0.362692654132843,\n",
       "  0.3594648241996765,\n",
       "  0.3556816279888153,\n",
       "  0.35206034779548645],\n",
       " 'val_accuracy': [0.5,\n",
       "  0.5,\n",
       "  0.4333333373069763,\n",
       "  0.4333333373069763,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.36666667461395264,\n",
       "  0.6000000238418579,\n",
       "  0.6666666865348816,\n",
       "  0.699999988079071,\n",
       "  0.699999988079071,\n",
       "  0.699999988079071,\n",
       "  0.699999988079071,\n",
       "  0.699999988079071,\n",
       "  0.7333333492279053,\n",
       "  0.7333333492279053,\n",
       "  0.7333333492279053,\n",
       "  0.7666666507720947,\n",
       "  0.7333333492279053,\n",
       "  0.800000011920929,\n",
       "  0.800000011920929,\n",
       "  0.800000011920929,\n",
       "  0.8666666746139526,\n",
       "  0.8333333134651184,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8666666746139526,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.9666666388511658,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/trainHistoryDict', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplots_adjust(top=2, right=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
